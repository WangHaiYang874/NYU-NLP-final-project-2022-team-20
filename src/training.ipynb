{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = '../data/mbti_full_pull_half_train.csv'\n",
    "df = pd.read_csv(train_csv_path, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body         87922\n",
       "mbti_type    87922\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_indices = []\n",
    "for k,group in df.groupby([\"mbti_type\"]).groups.items():\n",
    "    if len(group) > 10000:\n",
    "        new_indices.extend(group[:10000])\n",
    "    else:\n",
    "        new_indices.extend(group)\n",
    "df = df.loc[new_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Features import Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = '../models/features2021-12-11.model'\n",
    "\n",
    "try:\n",
    "    with open(modelName,'rb') as f:\n",
    "        feature_extractor = pickle.load(f)\n",
    "except:\n",
    "    feature_extractor = Features(df.body, '../data/stopwords.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the first layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## enumerating all the cognitive functions (With repeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I___\tE___\t_N__\t_S__\t__T_\t__F_\t___J\t___P\tIN__\tIS__\tEN__\tES__\tI_T_\tI_F_\tE_T_\tE_F_\tI__J\tI__P\tE__J\tE__P\t_NT_\t_NF_\t_ST_\t_SF_\t_N_J\t_N_P\t_S_J\t_S_P\t__TJ\t__TP\t__FJ\t__FP\tINT_\tINF_\tIST_\tISF_\tENT_\tENF_\tEST_\tESF_\tIN_J\tIN_P\tIS_J\tIS_P\tEN_J\tEN_P\tES_J\tES_P\tI_TJ\tI_TP\tI_FJ\tI_FP\tE_TJ\tE_TP\tE_FJ\tE_FP\t_NTJ\t_NTP\t_NFJ\t_NFP\t_STJ\t_STP\t_SFJ\t_SFP\tINTJ\tINTP\tINFJ\tINFP\tISTJ\tISTP\tISFJ\tISFP\tENTJ\tENTP\tENFJ\tENFP\tESTJ\tESTP\tESFJ\tESFP\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "types = ['IE','NS','TF','JP']\n",
    "\n",
    "deg1 = []\n",
    "\n",
    "for i in types:\n",
    "    for ii in i:\n",
    "        deg1.append(ii)\n",
    "\n",
    "deg2 = []\n",
    "for i,j, in combinations(types,2):\n",
    "    for ii in i:\n",
    "        for jj in j:\n",
    "            deg2.append(ii+jj)  \n",
    "\n",
    "deg3 = []\n",
    "for i,j,k in combinations(types,3):\n",
    "    for ii in i:\n",
    "        for jj in j:\n",
    "            for kk in k:\n",
    "                deg3.append(ii+jj+kk)\n",
    "\n",
    "deg4 = []\n",
    "for i,j,k,l in combinations(types,4):\n",
    "    for ii in i:\n",
    "        for jj in j:\n",
    "            for kk in k:\n",
    "                for ll in l:\n",
    "                    deg4.append(ii+jj+kk+ll)\n",
    "\n",
    "cog_funs = deg1 + deg2 + deg3 + deg4\n",
    "\n",
    "def normalize(s):\n",
    "    ret = ''\n",
    "    for type in types:\n",
    "        if type[0] in s:\n",
    "            ret += type[0]\n",
    "        elif type[1] in s:\n",
    "            ret += type[1]\n",
    "        else:\n",
    "            ret += '_'\n",
    "    return ret\n",
    "\n",
    "cog_funs = list(map(normalize,cog_funs))\n",
    "print('\\t'.join(cog_funs))\n",
    "print(len(cog_funs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are repeating elements in the above listed cog_funs, such as 'I___' and 'E___' are really the same thing, and I choose not to handle this repeatition.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what's left to do is to have feature extractions and then train binary classifier for each cognitive functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the feature extraction is trained and stored in a ../models/features______.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_match(y,y_):\n",
    "    for i,j in enumerate(y_):\n",
    "        if j == '_':\n",
    "            pass\n",
    "        elif j == y[i]:\n",
    "            pass\n",
    "        else:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_match('INTJ','_NT_'), check_match('INTJ','E___')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>mbti_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>572509</th>\n",
       "      <td>- For any number of reasons, sex always compli...</td>\n",
       "      <td>ENTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754043</th>\n",
       "      <td>I have several favorite books, but here are a ...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704479</th>\n",
       "      <td>I have a great relationship with my ESFJ mom. ...</td>\n",
       "      <td>ENTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796469</th>\n",
       "      <td>\"Bitch, you best back the fuck off\" is the fee...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563634</th>\n",
       "      <td>Hm. It sounds like Si might be a better fit fo...</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751260</th>\n",
       "      <td>Patience lady, may I ask what is the context o...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478158</th>\n",
       "      <td>I think the main sign is being in touch with o...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774634</th>\n",
       "      <td>Complaining about my tone is exactly what you'...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309992</th>\n",
       "      <td>As far as i know about the thinking and feelin...</td>\n",
       "      <td>ENTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168118</th>\n",
       "      <td>But I can have a job, and so can other women, ...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244104 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      body mbti_type\n",
       "572509   - For any number of reasons, sex always compli...      ENTP\n",
       "1754043  I have several favorite books, but here are a ...      INTJ\n",
       "704479   I have a great relationship with my ESFJ mom. ...      ENTJ\n",
       "796469   \"Bitch, you best back the fuck off\" is the fee...      INTJ\n",
       "1563634  Hm. It sounds like Si might be a better fit fo...      INFJ\n",
       "...                                                    ...       ...\n",
       "1751260  Patience lady, may I ask what is the context o...      INTJ\n",
       "478158   I think the main sign is being in touch with o...      INFP\n",
       "1774634  Complaining about my tone is exactly what you'...      INTJ\n",
       "1309992  As far as i know about the thinking and feelin...      ENTP\n",
       "1168118  But I can have a job, and so can other women, ...      INTP\n",
       "\n",
       "[244104 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the first layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNameSuffix = str(datetime.date.today())\n",
    "\n",
    "train_X = feature_extractor.get_features(df.body)\n",
    "train_y = df.mbti_type\n",
    "\n",
    "def flatten_one_row(feature):\n",
    "    tfidf, emoticon, topic = feature\n",
    "    tfidf = np.array(tfidf.todense()).flatten()\n",
    "    return np.concatenate([tfidf, emoticon, topic], axis=None)\n",
    "\n",
    "train_X = np.array([flatten_one_row(row) for row in train_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I___ training completed\n",
      "E___ training completed\n",
      "_N__ training completed\n",
      "_S__ training completed\n",
      "__T_ training completed\n",
      "__F_ training completed\n",
      "___J training completed\n",
      "___P training completed\n",
      "IN__ training completed\n",
      "IS__ training completed\n",
      "EN__ training completed\n",
      "ES__ training completed\n",
      "I_T_ training completed\n",
      "I_F_ training completed\n",
      "E_T_ training completed\n",
      "E_F_ training completed\n",
      "I__J training completed\n",
      "I__P training completed\n",
      "E__J training completed\n",
      "E__P training completed\n",
      "_NT_ training completed\n",
      "_NF_ training completed\n",
      "_ST_ training completed\n",
      "_SF_ training completed\n",
      "_N_J training completed\n",
      "_N_P training completed\n",
      "_S_J training completed\n",
      "_S_P training completed\n",
      "__TJ training completed\n",
      "__TP training completed\n",
      "__FJ training completed\n",
      "__FP training completed\n",
      "INT_ training completed\n",
      "INF_ training completed\n",
      "IST_ training completed\n",
      "ISF_ training completed\n",
      "ENT_ training completed\n",
      "ENF_ training completed\n",
      "EST_ training completed\n",
      "ESF_ training completed\n",
      "IN_J training completed\n",
      "IN_P training completed\n",
      "IS_J training completed\n",
      "IS_P training completed\n",
      "EN_J training completed\n",
      "EN_P training completed\n",
      "ES_J training completed\n",
      "ES_P training completed\n",
      "I_TJ training completed\n",
      "I_TP training completed\n",
      "I_FJ training completed\n",
      "I_FP training completed\n",
      "E_TJ training completed\n",
      "E_TP training completed\n",
      "E_FJ training completed\n",
      "E_FP training completed\n",
      "_NTJ training completed\n",
      "_NTP training completed\n",
      "_NFJ training completed\n",
      "_NFP training completed\n",
      "_STJ training completed\n",
      "_STP training completed\n",
      "_SFJ training completed\n",
      "_SFP training completed\n",
      "INTJ training completed\n",
      "INTP training completed\n",
      "INFJ training completed\n",
      "INFP training completed\n",
      "ISTJ training completed\n",
      "ISTP training completed\n",
      "ISFJ training completed\n",
      "ISFP training completed\n",
      "ENTJ training completed\n",
      "ENTP training completed\n",
      "ENFJ training completed\n",
      "ENFP training completed\n",
      "ESTJ training completed\n",
      "ESTP training completed\n",
      "ESFJ training completed\n",
      "ESFP training completed\n"
     ]
    }
   ],
   "source": [
    "for model in cog_funs:\n",
    "    \n",
    "    train_yy = [check_match(i,model) for i in train_y]\n",
    "    \n",
    "    classifier = RandomForestClassifier(n_estimators=8)\n",
    "    # todo: perhaps find a better classifier? \n",
    "    \n",
    "    classifier.fit(train_X, train_yy)\n",
    "    \n",
    "    with open('../models/first_layer/'  + model + modelNameSuffix + '.model','wb') as f:\n",
    "        pickle.dump(classifier,f)\n",
    "    print(model +' training completed')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(train_csv_path, index_col=0)\n",
    "full_train_X = feature_extractor.get_features(full_df.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "full_train_X = np.array([flatten_one_row(row) for row in full_train_X ])\n",
    "np.save(\"../data/train_x.np\",full_train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The second layer model\n",
    "\n",
    "The inputs of the second layer model should be\n",
    "- cognitive functions, there are roughly 80 of them. With a bigger weight\n",
    "- the dimension-reducted output of the features. The features supposed have a really large dimension of 10k, we should perhaps reduct it down to 1k? \n",
    "\n",
    "And the layers of the NN should be\n",
    "- a few linear layers, plus activations\n",
    "\n",
    "I have already written some codes in `development.ipynb`. Those codes should be moved here. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
