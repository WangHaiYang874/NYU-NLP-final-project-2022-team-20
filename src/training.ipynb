{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from Features import Features\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = '../data/mbti_full_pull_half_train.csv'\n",
    "# train_csv_path = '/mnt/c/Users/haiya/Downloads/finalp/mbti_full_pull_half_train.csv'\n",
    "\n",
    "df = pd.read_csv(train_csv_path, index_col=0)\n",
    "\n",
    "# Both the train and test are sample from the training mbti_full_pull_half_train.csv. So this will not affect the evaluation later\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(df.body, df.mbti_type, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbti_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENFJ</th>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENFP</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTJ</th>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTP</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESFJ</th>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESFP</th>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTJ</th>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTP</th>\n",
       "      <td>3757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFJ</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFP</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTP</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISFJ</th>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISFP</th>\n",
       "      <td>1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISTJ</th>\n",
       "      <td>2380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISTP</th>\n",
       "      <td>7209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            body\n",
       "mbti_type       \n",
       "ENFJ        3279\n",
       "ENFP       10000\n",
       "ENTJ        6614\n",
       "ENTP       10000\n",
       "ESFJ         346\n",
       "ESFP         695\n",
       "ESTJ        1043\n",
       "ESTP        3757\n",
       "INFJ       10000\n",
       "INFP       10000\n",
       "INTJ       10000\n",
       "INTP       10000\n",
       "ISFJ        1146\n",
       "ISFP        1453\n",
       "ISTJ        2380\n",
       "ISTP        7209"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is reducing the size of the training dataset\n",
    "new_indices = []\n",
    "for k,group in df.groupby([\"mbti_type\"]).groups.items():\n",
    "    if len(group) > 10000:\n",
    "        new_indices.extend(group[:10000])\n",
    "    else:\n",
    "        new_indices.extend(group)\n",
    "df = df.loc[new_indices]\n",
    "df.groupby(['mbti_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = '../models/features2021-12-14.model'\n",
    "\n",
    "try:\n",
    "    # the model can be loaded\n",
    "    with open(modelName,'rb') as f:\n",
    "        feature_extractor = pickle.load(f)\n",
    "except:\n",
    "    # training the model\n",
    "    feature_extractor = Features(df.body, '../data/stopwords.txt')\n",
    "    feature_extractor.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the first layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## enumerating all the cognitive functions (With repeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I___\tE___\t_N__\t_S__\t__T_\t__F_\t___J\t___P\tIN__\tIS__\tEN__\tES__\tI_T_\tI_F_\tE_T_\tE_F_\tI__J\tI__P\tE__J\tE__P\t_NT_\t_NF_\t_ST_\t_SF_\t_N_J\t_N_P\t_S_J\t_S_P\t__TJ\t__TP\t__FJ\t__FP\tINT_\tINF_\tIST_\tISF_\tENT_\tENF_\tEST_\tESF_\tIN_J\tIN_P\tIS_J\tIS_P\tEN_J\tEN_P\tES_J\tES_P\tI_TJ\tI_TP\tI_FJ\tI_FP\tE_TJ\tE_TP\tE_FJ\tE_FP\t_NTJ\t_NTP\t_NFJ\t_NFP\t_STJ\t_STP\t_SFJ\t_SFP\tINTJ\tINTP\tINFJ\tINFP\tISTJ\tISTP\tISFJ\tISFP\tENTJ\tENTP\tENFJ\tENFP\tESTJ\tESTP\tESFJ\tESFP\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "types = ['IE','NS','TF','JP']\n",
    "\n",
    "deg1 = []\n",
    "\n",
    "for i in types:\n",
    "    for ii in i:\n",
    "        deg1.append(ii)\n",
    "\n",
    "deg2 = []\n",
    "for i,j, in combinations(types,2):\n",
    "    for ii in i:\n",
    "        for jj in j:\n",
    "            deg2.append(ii+jj)  \n",
    "\n",
    "deg3 = []\n",
    "for i,j,k in combinations(types,3):\n",
    "    for ii in i:\n",
    "        for jj in j:\n",
    "            for kk in k:\n",
    "                deg3.append(ii+jj+kk)\n",
    "\n",
    "deg4 = []\n",
    "for i,j,k,l in combinations(types,4):\n",
    "    for ii in i:\n",
    "        for jj in j:\n",
    "            for kk in k:\n",
    "                for ll in l:\n",
    "                    deg4.append(ii+jj+kk+ll)\n",
    "\n",
    "cog_funs = deg1 + deg2 + deg3 + deg4\n",
    "\n",
    "def normalize(s):\n",
    "    ret = ''\n",
    "    for type in types:\n",
    "        if type[0] in s:\n",
    "            ret += type[0]\n",
    "        elif type[1] in s:\n",
    "            ret += type[1]\n",
    "        else:\n",
    "            ret += '_'\n",
    "    return ret\n",
    "\n",
    "cog_funs = list(map(normalize,cog_funs))\n",
    "print('\\t'.join(cog_funs))\n",
    "print(len(cog_funs))\n",
    "cog_funs = {i:None for i in cog_funs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are repeating elements in the above listed cog_funs, such as 'I___' and 'E___' are really the same thing, and I choose not to handle this repeatition.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what's left to do is to have feature extractions and then train binary classifier for each cognitive functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the feature extraction is trained and stored in a ../models/features______.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the first layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_match(y,y_):\n",
    "    for i,j in enumerate(y_):\n",
    "        if j == '_':\n",
    "            pass\n",
    "        elif j == y[i]:\n",
    "            pass\n",
    "        else:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNameSuffix = '2021-12-13'\n",
    "\n",
    "X_train1 = feature_extractor.get_features(X_train)\n",
    "X_test1 = feature_extractor.get_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in cog_funs.keys():\n",
    "    try:\n",
    "        with open('../models/first_layer/'  + model + modelNameSuffix + '.model','rb') as f:\n",
    "            cog_funs[model] = pickle.load(f)\n",
    "    except:\n",
    "        \n",
    "        train_yy = [check_match(i,model) for i in train_y]\n",
    "        \n",
    "        classifier = RandomForestClassifier(n_estimators=10)\n",
    "        \n",
    "        classifier.fit(train_X, train_yy)\n",
    "        \n",
    "        with open('../models/first_layer/'  + model + modelNameSuffix + '.model','wb') as f:\n",
    "            pickle.dump(classifier,f)\n",
    "            cog_funs[model] = classifier\n",
    "        print(model +' training completed', end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_predict(train_X):\n",
    "    return np.array([cog_funs[model].predict_proba(train_X)[:,0] \\\n",
    "        for model in sorted(list(cog_funs))]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The second layer model: random forest\n",
    "\n",
    "The inputs of the second layer model should be\n",
    "- ✔ cognitive functions, there are roughly 80 of them. With a bigger weight\n",
    "- ❌ the features. \n",
    "\n",
    "We have imagined to use a second layer as a NN, which takes both the cognitive functions and the features. However, we realized that NN is too costly and really not necessary, as we have a first layer with incredible accuracy. So we will use a simple _random forest_ for the second layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = cf_predict(X_train1)\n",
    "X_test2 = cf_predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I E N S T F J P I 0.919433927130532\n",
      "E 0.9193966854943827\n",
      "N 0.9991434423685681\n",
      "S 0.9992551672770157\n",
      "T 0.8409037303705543\n",
      "F 0.8412885606107628\n",
      "J 0.7704301408975235\n",
      "P 0.7715473899819999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "deg1 = {i:None for i in deg1}\n",
    "\n",
    "for i in deg1:\n",
    "    clf = RandomForestClassifier()\n",
    "    yy_train = [i in j for j in y_train]\n",
    "    clf.fit(X_train2,yy_train)\n",
    "    deg1[i] = clf\n",
    "    print(i,end=' ')\n",
    "\n",
    "for i,clf in deg1.items():\n",
    "    yy_test = [i in j for j in y_test]\n",
    "    print(i, accuracy_score(yy_test, clf.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above result will be my second layer model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results shown implies that we can be certain about the personality in the `N versus S`, `T versus F`, `J versus P` dimension. The only thing uncertain is `Introverts versus Extroverts`. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
